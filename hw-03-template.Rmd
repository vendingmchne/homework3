---
title: "hw-03"
author: "Raven Callaghan (S2486713)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
## **DO NOT EDIT THIS CODE CHUNK**
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
```


## Data Load

```{r read_data}
gss16<-read.csv("data/gss16.csv")
```

## Data preparation before modelling

The `gss16` data set needs to be prepared prior to modelling. This is not an assessed component to your assignment, but it is an important part of the data science process. Carefully copy the following code into the beginning of your `.Rmd` file and ensure that you understand how the data has been prepared.

### Cleaning and selecting rows 

Create a new data frame called `gss16_advfront` that includes the variables `advfront`, `emailhr` (Number of hours spent on email weekly), `educ` (education level), `polviews` (political views) and `wrkstat` (working status). Remove any row that contains any `NA`s using the `drop_na()` command

```{r}
gss16_advfront <- gss16 %>%
  select(advfront, emailhr, educ, polviews, wrkstat) %>%
  drop_na()
```

### Re-levelling `advfront`

The `advfront` variable contains responses to the question "Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government." The possible answers are on the 5-point Likert scale: `"Strongly agree"`, `"Agree"`, `"Dont know"`, `"Disagree"` and `"Strongly disagree"`. For the purpose of this assignment, the `advfront` variable needs to be transformed such that it has two levels: 

* `"Agree"` - combining the options `"Strongly agree"` and `"Agree"`.
* `"Not agree"` - combining the options `"Dont know"`, `"Disagree"` and `"Strongly disagree"`.

The following code does that this re-levelling:

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(
    advfront = case_when(
      advfront == "Strongly agree" ~ "Agree",
      advfront == "Agree" ~ "Agree",
      TRUE ~ "Not agree"
    ),
    advfront = fct_relevel(advfront, "Not agree", "Agree")
  )
```


### Re-levelling `polviews`


```{marginfigure}
You can do this in various ways. One option is to use the `str_detect()` function to detect the existence of words like liberal or conservative. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the `str_detect()` function, you can use "[Ll]iberal" and "[Cc]onservative". But feel free to solve the problem however you like, this is just one option!
```

The `polviews` variable contains information about the participant's political position within 7 categories ranging from `"Extremely liberal"` to `"Extrmly conservative"`. Here we wish to simplify the range of options to 3 categories - `"Conservative"` , `"Moderate"`, and `"Liberal"`. This is achieved via the following code:

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(
    polviews = case_when(
      str_detect(polviews, "[Cc]onservative") ~ "Conservative",
      str_detect(polviews, "[Ll]iberal") ~ "Liberal",
      TRUE ~ polviews
    ),
    polviews = fct_relevel(polviews, "Conservative", "Moderate", "Liberal")
  )
```

Please see [chapter 14 of R for Data Science](https://r4ds.had.co.nz/strings.html) for more on string processing commands.

You now have the cleaned and pre-processe data to use for modelling, you can continue with the `gss16_advfront` for the following questions. 

## Exercise 1: Create a linear regression model

Consider the numerical values `educ` and `emailhr` from your new data set `gss16_advfront`.

a) Fit a linear regression model to predicting `emailhr` based on the `educ`. From your output, state the formula for the line-of-best fit and give an interpretation of the `emailhr` estimate.

b) Comment on the overall performance of the linear regression model. Support your statements with an appropriate data visualisation and model fit statistics.

```{r}
educ_emailhr_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(emailhr ~ educ, data = gss16_advfront)
educ_emailhr_fit


educ_emailhr_augfit <- augment(educ_emailhr_fit$fit)
ggplot(data = educ_emailhr_augfit, mapping = aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Prediction", y = "Residuals")

  ggplot(data = gss16_advfront, mapping = aes(x = educ, y = emailhr)) + geom_jitter() + geom_smooth(method = "lm")

glance(educ_emailhr_fit)$r.squared
```
The formula for the linear regression model of education level against hours spent using email is (emailhr) = -2.7573 + 0.6854(educ). 

This means that for every unit of education level increases, the number of weekly hours spent using email increases by 0.6854 hours. If someone were to have an education level of 0, they would by this linear model be expected to spend -2.7573 hours using their email weekly, which makes no sense in context as time cannot hold a negative value. 

Looking at the visualisation of the residuals, there isn't a particularly clear and definite pattern, however it is clear that the magnitude of residuals is tending to increase with education level, which suggests that a linear model may not be the most effective method of modelling these two variables. In addition, the model has an r squared value of 0.02912, which means 2.912% of the variability in the emailhr values can be explained by the values in educ, which is not a lot. 

## Exercise 2: Create a workflow to fit a model

In this part, we're going to build a model to predict whether someone agrees or doesn't agree with the following statement:

Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.

The responses to the question on the GSS about this statement are in the `advfront` variable, in the `gss16_advfront` data that you obtained.

First, use the following code to split the dataset into a training dataset (`gss16_train`) and a testing dataset (`gss16_test`). This code splits the data into 75\% training and 25\% testing.

```{r split-data}
set.seed(1234)
gss16_split <- initial_split(gss16_advfront)
gss16_train <- training(gss16_split)
gss16_test  <- testing(gss16_split)
```

a) Build a workflow for the training data that consists of a recipe (`gss16_rec_1`) and a model (`gss16_mod_1`). Name this workflow `gss16_wflow_1`.
    
The recipe (named `gss16_rec_1`) should contain the following steps for predicting `advfront` from `educ`:

  - `step_dummy()` to create dummy variables for `all_nominal()` variables that are predictors, i.e. not "outcomes". You can select outcomes using `all_outcomes()`

  - The model (named `gss16_mod_1`) should specify a model that is appropriate for the data as well as the computational engine.

```{r}
gss16_rec_1 <- recipe(advfront ~ educ, data = gss16_train) %>%
  step_dummy(all_nominal_predictors(), -all_outcomes())

gss16_mod_1 <- logistic_reg() %>%
  set_engine("glm")

gss16_wflow_1 <- workflow() %>%
  add_model(gss16_mod_1) %>%
  add_recipe(gss16_rec_1)
gss16_wflow_1

```

b) Explain why you have chosen the model that you have selected.

I have chosen to use a logistic regression model because the response variable being modelled is a categorical variable which can be expressed as a factor (of Agree and Disagree), whereas a linear regression model would be more appropriate if the data were numerically expressed. 

## Exercise 3: Logistic regression with single predictor

a) Apply the workflow you defined earlier to the training dataset and named the model as `gss16_fit_1`. Display the resulting tibble containing the fitted model parameters. 

```{r}

```

b) Use the fitted models to predict the test data, plot the ROC curves for the predictions.

```{r}

```

## Exercise 4: Logistic regression modelling and interpretation

We are now going to model `advfront` using the explanatory variables `polviews`, `wrkstat`, and `educ`.

a) Build a new workflow for the training data that consists of a recipe (`gss16_rec_2`) and a model (`gss16_mod_2`). Name this workflow `gss16_wflow_2`. You can simply **copy, paste and edit** the code from earlier.
    
Now the new recipe (named `gss16_rec_2`) should contain the followings for predicting `advfront` from `polviews`, `wrkstat`, and `educ`:

  - `step_dummy()` to create dummy variables for `all_nominal()` variables that are predictors, i.e. not "outcomes". You can select outcomes using `all_outcomes()`

  - The model (named `gss16_mod_2`) should specify a model that is appropriate for the data as well as the computational engine.
  
Apply the new workflow to the training dataset and create a new model fit 
named as `gss16_fit_2`. 

Then use the fitted models to predict the test data, plot the ROC curve for the predictions for both models, and calculate the areas under the ROC curves.

```{r}

```

b) Comment on which model performs better 

  * the model only including `educ`, as model 1 (`gss16_fit_1`) 
  * the model including `polviews`, `wrkstat`, and `educ` with `gss16_split` as model 2 (`gss16_fit_2`)
  
Explain your reasoning.

```{r}

```



